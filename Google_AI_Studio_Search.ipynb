{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Google AI Studio File Search Tool (Optimized)\n",
    "Fast search for 1000+ files without extension in your \"/Google AI Studio\" drive folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML, display\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# Install tqdm for progress bars if not already installed\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"tqdm\"])\n",
    "    from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "DRIVE_FOLDER = '/content/drive/My Drive/Google AI Studio'\n",
    "ENCODING = 'utf-8'\n",
    "MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB - skip larger files\n",
    "NUM_WORKERS = 4  # Parallel threads for searching\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted!\")\n",
    "print(f\"‚öôÔ∏è  Using {NUM_WORKERS} parallel workers for fast searching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files_without_extension(folder_path, max_size=MAX_FILE_SIZE):\n",
    "    \"\"\"Find all files without extension in the specified folder and subfolders\"\"\"\n",
    "    files_without_ext = []\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"‚ùå Folder not found: {folder_path}\")\n",
    "        return files_without_ext\n",
    "\n",
    "    try:\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # Check if file has no extension (no dot in filename, or dot is at the start)\n",
    "                if '.' not in file or file.startswith('.'):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        file_size = os.path.getsize(full_path)\n",
    "                        # Skip files that are too large (likely binary)\n",
    "                        if file_size <= max_size:\n",
    "                            files_without_ext.append((full_path, file_size))\n",
    "                    except (OSError, PermissionError):\n",
    "                        pass\n",
    "    except PermissionError as e:\n",
    "        print(f\"‚ö†Ô∏è  Permission denied: {e}\")\n",
    "\n",
    "    # Sort by file size (smaller files first for faster initial results)\n",
    "    files_without_ext.sort(key=lambda x: x[1])\n",
    "    return [f[0] for f in files_without_ext]\n",
    "\n",
    "# Find files without extension\n",
    "print(\"üìÇ Scanning for files without extension...\")\n",
    "start_time = time.time()\n",
    "files_without_ext = find_files_without_extension(DRIVE_FOLDER)\n",
    "scan_time = time.time() - start_time\n",
    "\n",
    "if files_without_ext:\n",
    "    total_size = sum(os.path.getsize(f) for f in files_without_ext if os.path.exists(f)) / (1024*1024)\n",
    "    print(f\"‚úÖ Found {len(files_without_ext)} files ({total_size:.1f}MB) in {scan_time:.2f}s\\n\")\n",
    "    print(\"Sample files:\")\n",
    "    for file in files_without_ext[:10]:\n",
    "        size = os.path.getsize(file) / 1024\n",
    "        print(f\"  ‚Ä¢ {file} ({size:.1f}KB)\")\n",
    "    if len(files_without_ext) > 10:\n",
    "        print(f\"  ... and {len(files_without_ext) - 10} more\")\n",
    "else:\n",
    "    print(\"üì≠ No files without extension found\")\n",
    "\n",
    "print(f\"\\nTotal files: {len(files_without_ext)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_file(file_path, search_term, case_sensitive=False, flags=0):\n",
    "    \"\"\"Search for a term in a single file - optimized for parallel execution\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=ENCODING, errors='ignore') as f:\n",
    "            # Read file in chunks for very large files\n",
    "            content = f.read()\n",
    "            \n",
    "            try:\n",
    "                matches = list(re.finditer(search_term, content, flags))\n",
    "            except re.error as e:\n",
    "                return [(file_path, 0, f'‚ùå Regex error: {e}', '', 0)]\n",
    "            \n",
    "            if matches:\n",
    "                lines = content.split('\\n')\n",
    "                for match in matches:\n",
    "                    pos = match.start()\n",
    "                    line_num = content[:pos].count('\\n') + 1\n",
    "                    line_content = lines[line_num - 1] if line_num <= len(lines) else \"\"\n",
    "                    \n",
    "                    results.append((file_path, line_num, match.group(), line_content, pos))\n",
    "    except Exception as e:\n",
    "        pass  # Silently skip files that can't be read\n",
    "    \n",
    "    return results\n",
    "\n",
    "def search_in_files_parallel(files, search_term, case_sensitive=False, num_workers=NUM_WORKERS):\n",
    "    \"\"\"Search for a term in files using parallel processing\"\"\"\n",
    "    results = []\n",
    "    flags = 0 if case_sensitive else re.IGNORECASE\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        futures = {\n",
    "            executor.submit(search_in_file, file_path, search_term, case_sensitive, flags): file_path\n",
    "            for file_path in files\n",
    "        }\n",
    "        \n",
    "        # Collect results with progress bar\n",
    "        with tqdm(total=len(files), desc=\"üîç Searching\", unit=\"file\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                file_results = future.result()\n",
    "                results.extend(file_results)\n",
    "                pbar.update(1)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def display_results_html(results, limit=50):\n",
    "    \"\"\"Display search results in HTML format\"\"\"\n",
    "    if not results:\n",
    "        display(HTML(\"<p><strong>üì≠ No matches found</strong></p>\"))\n",
    "        return\n",
    "\n",
    "    html = f\"<p><strong>‚úÖ Found {len(results)} matches</strong></p>\"\n",
    "    html += \"<div style='border: 1px solid #ddd; padding: 10px; border-radius: 5px; max-height: 600px; overflow-y: auto;'>\"\n",
    "\n",
    "    for i, (file_path, line_num, match, line_content, pos) in enumerate(results[:limit], 1):\n",
    "        file_name = file_path.replace('/content/drive/My Drive/', '')\n",
    "        html += f\"<div style='margin-bottom: 15px; padding-bottom: 10px; border-bottom: 1px solid #eee;'>\"\n",
    "        html += f\"<p><strong>{i}. {file_name}</strong></p>\"\n",
    "        html += f\"<p style='color: #666; font-size: 12px;'>Line {line_num}</p>\"\n",
    "        html += f\"<p style='background-color: #f5f5f5; padding: 5px; border-radius: 3px; word-break: break-all;'>\"\n",
    "        html += f\"<code><strong style='color: #d9534f;'>{match}</strong></code></p>\"\n",
    "        \n",
    "        if line_content:\n",
    "            context = line_content[:120]\n",
    "            if len(line_content) > 120:\n",
    "                context += \"...\"\n",
    "            html += f\"<p style='color: #999; font-size: 12px;'><em>{context}</em></p>\"\n",
    "        html += \"</div>\"\n",
    "\n",
    "    if len(results) > limit:\n",
    "        html += f\"<p><em>... and {len(results) - limit} more matches</em></p>\"\n",
    "\n",
    "    html += \"</div>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "print(\"‚ö° Optimized search functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast search - modify these values to search\n",
    "search_term = \"TODO\"  # Change this to your search term\n",
    "case_sensitive = False  # Set to True for case-sensitive search\n",
    "\n",
    "print(f\"üîç Searching for '{search_term}'...\\n\")\n",
    "start_time = time.time()\n",
    "results = search_in_files_parallel(files_without_ext, search_term, case_sensitive, num_workers=4)\n",
    "search_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(results)} matches in {search_time:.2f}s\")\n",
    "print(f\"Searched {len(files_without_ext)} files at ~{len(files_without_ext)/search_time:.0f} files/second\\n\")\n",
    "\n",
    "display_results_html(results, limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced regex search example\n",
    "search_term = r\"def\\s+\\w+\\(\"  # Find function definitions\n",
    "case_sensitive = True\n",
    "\n",
    "print(f\"üîç Searching with regex: '{search_term}'...\\n\")\n",
    "start_time = time.time()\n",
    "results = search_in_files_parallel(files_without_ext, search_term, case_sensitive)\n",
    "search_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(results)} matches in {search_time:.2f}s\\n\")\n",
    "display_results_html(results, limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison: single vs parallel\n",
    "import time\n",
    "\n",
    "test_search = \"class\"\n",
    "test_files = files_without_ext[:50]  # Test with first 50 files\n",
    "\n",
    "print(f\"üìä Performance Test: Searching for '{test_search}' in {len(test_files)} files\\n\")\n",
    "\n",
    "# Single threaded (slow)\n",
    "print(\"‚è±Ô∏è  Single-threaded search...\")\n",
    "start = time.time()\n",
    "single_results = []\n",
    "flags = re.IGNORECASE\n",
    "for f in test_files:\n",
    "    single_results.extend(search_in_file(f, test_search, False, flags))\n",
    "single_time = time.time() - start\n",
    "print(f\"   Time: {single_time:.2f}s\")\n",
    "\n",
    "# Multi-threaded (fast)\n",
    "print(\"\\n‚ö° Parallel search (4 workers)...\")\n",
    "start = time.time()\n",
    "parallel_results = search_in_files_parallel(test_files, test_search, False, num_workers=4)\n",
    "parallel_time = time.time() - start\n",
    "print(f\"   Time: {parallel_time:.2f}s\")\n",
    "\n",
    "print(f\"\\nüìà Speedup: {single_time/parallel_time:.1f}x faster with parallel processing!\")\n",
    "print(f\"   Found {len(parallel_results)} matches\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python3",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
